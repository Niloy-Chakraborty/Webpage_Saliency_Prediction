# -*- coding: utf-8 -*-
"""Generalization_Cross_Correlation_and_NSS_Calculation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vnukUIVTL8Hzpxuizc8WSgOza1pAaSTR

Script Name: Cross_Correlation_and_NSS_Calculation.ipynb

Functionality: This script invokes the following functionality for evaluating models' generalization capabilities

               1) Calculate Pearson Correlation
               2) Calculate Normalized Scanpath Saliency
"""

# Connect to Google colab
# from google.colab import drive
# drive.mount('/content/drive')

# import libraries
import cv2
import matplotlib.pyplot as plt
import numpy as np
import os
import pandas as pd

"""
Function Name:  nss()
Parameters: Y,P,img_list
Functionality: This function
               1) Calculate the NSS score between Ground Truth and the predicted
                  Saliency for different techniques, like Itti-koch, Deep Gaze, 
                  FCN etc
               2) Appends the scores in a list and calculate Max, Min and Avg 
                  score.
Returns: max, min and avg score
"""


def nss(Y, P, img_list):
    lis = []
    for gt, s_map, im in zip(Y, P, img_list):
        print(im)

        gt = np.ceil(gt / 255)
        # print(gt.max())
        x, y = np.where(gt == 1)
        s_map_norm = (s_map - np.mean(s_map)) / np.std(s_map)

        temp = []
        for i in zip(x, y):
            temp.append(s_map_norm[i[0], i[1]])
        a = np.mean(temp)
        print("NSS" + im + ": " + str(a))
        lis.append(a)

    # print("MAX NSS: "+ str(max(lis)))
    # print("MIN NSS: "+ str(min(lis)))
    # print("AVG NSS: "+ str(sum(lis)/len(lis)))
    return max(lis), min(lis), sum(lis) / len(lis)


"""
Function Name:  cross_correlation()
Parameters: Y,P,img_list
Functionality: This function
               1) Calculate the Correlation score between Ground Truth and the 
                  predicted Saliency for different techniques, like Itti-koch, Deep Gaze, 
                  FCN etc
               2) Appends the scores in a list and calculate Max, Min and Avg 
                  score.
Returns: max, min and avg score
"""


def cal_correlation(Y, P, img_list):
    lis = []
    for map1, map2, im in zip(Y, P, img_list):
        # Show the images
        # plt.imshow(map1)
        # plt.title("Ground Truth: " + im)
        # plt.show()
        # plt.imshow(map2)
        # plt.title("Saliency: " + im)
        # plt.show()

        # Calculate cross-correlation
        map1 = (map1 - map1.mean()) / map1.std()
        map2 = (map2 - map2.mean()) / map2.std()
        a = np.corrcoef(map1.flat, map2.flat)
        # print(a)
        lis.append(a[0][1])

        print("CC for " + im + " is: " + str(a[0][1]))

    # print("MAX CC: "+ str(max(lis)))
    # print("MIN CC: "+ str(min(lis)))
    # print("AVG CC: "+ str(sum(lis)/len(lis)))
    return max(lis), min(lis), sum(lis) / len(lis)


# Define your own path to the data directory
path_to_data = "E:\Webpage_Saliency_Prediction\Prediction_and_Analysis\\"

# Path for result data folders for FiWi data, MassVis data and MIT dataset using FCN16 model

# FiWi
FiWi_gt = path_to_data + "Generalization_Data/FiWi/Ground_Truth_Eyemap/"
FiWi_pi = path_to_data + "Generalization_Data/FiWi/predicted_images/"

# MassVis
MassVis_gt = path_to_data + "Generalization_Data/Massvis/valid_imp/"
MassVis_pi = path_to_data + "Generalization_Data/Massvis/predicted_image/"

# MIT
MIT_gt = path_to_data + "Generalization_Data/MIT_Dataset/test_gt/"
MIT_pi = path_to_data + "Generalization_Data/MIT_Dataset/predicted_image/"

# Create a dictionary using the above mentioned paths
dir_data_pred_dict = {"FiWI": {"gt": FiWi_gt, "pi": FiWi_pi}, "MassVis": {"gt": MassVis_gt, "pi": MassVis_pi},
                      "MIT": {"gt": MIT_gt, "pi": MIT_pi}}

print(dir_data_pred_dict.keys())
for i, k in dir_data_pred_dict.items():
    for j, l in dir_data_pred_dict[i].items():
        print(l)
        exit

"""
Function Name: return_image_size()
Functionality: This function takes path of a predicted image and returns the 
                size of the image
Parameter:path
Returns: img.shape[0],img.shape[1]

"""


def return_image_size(path):
    img = cv2.imread(path, 1)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    return img.shape[0], img.shape[1]


"""
Function Name: Groung_Image_Arr()
Functionality: 1) BGR-GRAY conversion
                 2) Resizing to height*weight
                 3) values range from 0 to 255
Parameter:path, width, height,title
Returns: label

"""


def Groung_Image_Arr(path, width, height, title):
    # print(path)
    # print(title)

    img = cv2.imread(path, 1)
    if img is None:
        path.endswith(".jpg")
        path = path.split(".")
        # print(path)
        path = path[0] + ".jpeg"
        img = cv2.imread(path, 1)
        # print(img)
    # print(img)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    img = cv2.resize(img, (width, height))
    label = np.array(img, dtype=np.uint8)  # values range from 0 to 255
    # print(label.max())
    return label


"""
Function Name: pred_img_Arr()
Functionality: 1) BGR-GRAY conversion
                 2) Resizing to height*weight
                 3) values range from 0 to 255
Parameter:path, width, height,title
Returns: label

"""


def pred_img_Arr(path, width, height, title):
    img = cv2.imread(path, 1)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # img = cv2.resize(img, (width, height))
    label = np.array(img, dtype=np.uint8)  # values range from 0 to 255
    # print(label.max())
    return label


dic = {}
metric_name = "correlation"  # correlation, NSS

for i, j in dir_data_pred_dict.items():
    #     print(i)
    #     print(j)
    #     input_width, input_height = return_image_size(dir_data_pred+pred_saliency_data[0])
    #     if input_width>224:
    #         input_width, input_height = 224,224

    for dir_data_name, dir_data in dir_data_pred_dict[i].items():
        # print(dir_data_name)
        # print(dir_data)

        pred_saliency_data = os.listdir(dir_data)
        pred_saliency_data.sort()
        # print("salienvy data: ", saliency_data)
        input_width, input_height = return_image_size(dir_data + pred_saliency_data[0])

        # Salicon returns size more than 224*224, so reduce it to 224*224
        if input_width > 224:
            input_width, input_height = 224, 224

        if dir_data_name == "gt":
            dir_data_gt = dir_data
            # read groud data directory and sort
            saliency_data = os.listdir(dir_data)
            # print("saliency data: ", saliency_data)
            saliency_data.sort()
            # print("sorted",saliency_data)
            continue

        elif dir_data_name == "pi":
            dir_data_pred = dir_data
            # read predicted data directory and sort
            pred_saliency_data = os.listdir(dir_data_pred)
            pred_saliency_data.sort()
            # print("sorted",pred_saliency_data)

        Y = []
        P = []
        img_list = []

        # create nd array for evaluation
        for im in saliency_data:
            print(im)
            Y.append(Groung_Image_Arr(dir_data_gt + im, input_width, input_height, im))
            img_list.append(im)

        for im_pred in pred_saliency_data:
            P.append(pred_img_Arr(dir_data_pred + im_pred, input_width, input_height, im))

        Y = np.array(Y)
        # print(Y.shape)

        P = np.array(P)
        # print(P.shape)

        if metric_name == "NSS":
            # NSS
            mx, mn, avg = nss(Y, P, img_list)

        elif metric_name == "correlation":
            # Correlation
            mx, mn, avg = cal_correlation(Y, P, img_list)

        # Save the data in a dictionary
        dic_res = {"max": mx, "min": mn, "avg": avg}

        # print(dic_res)
        dic[i] = dic_res

        print("###############################################################")

    print(dic)
    df = pd.DataFrame(dic)
    df.to_csv(path_to_data + "/Generalization_Results/" + str(metric_name) + "results.csv")

"""Plot Metric Results"""

df_new = df.T
print(df_new)

# df= df.reset_index()

fig = df_new.plot(kind='bar')
# plt.margins(0.02)
plt.ylabel(metric_name + " Score")
plt.xlabel('Models')
fig.set_xticklabels(df_new.T.columns, rotation=45, ha="right")
plt.tight_layout()

# plt.grid(True)

# Save Plots
plt.savefig(path_to_data + "/Generalization_Results/" + str(metric_name) + ".png")
plt.show()
