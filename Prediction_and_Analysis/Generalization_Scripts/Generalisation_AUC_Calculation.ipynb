{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Generalisation_AUC_Calculation.ipynb",
   "provenance": [
    {
     "file_id": "1cFIzR8fO9_ovsf_WCZi5SwuqLgHicuHu",
     "timestamp": 1581963857386
    },
    {
     "file_id": "1oGxP6LhXpnRjAessWGIIeC__P-h392XF",
     "timestamp": 1580677275782
    },
    {
     "file_id": "19p7OrGfxQqArz3OfLDA4q3MDABGAv7tG",
     "timestamp": 1580644632311
    }
   ],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "ItFKZi3G9oJQ",
    "colab_type": "code",
    "outputId": "d5899edc-5ab7-428d-c843-bd270e284d8a",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1581974063274,
     "user_tz": -330,
     "elapsed": 886,
     "user": {
      "displayName": "Niloy Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAeDh1ZmOF_gqNBKQeZx-iTQhGRzkKZDJAA9so4=s64",
      "userId": "05129198731213717808"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Connect to Google Colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4f5a7ee88d02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Connect to Google Colab\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'google.colab'"
     ],
     "evalue": "No module named 'google.colab'",
     "ename": "ImportError",
     "output_type": "error"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pIVUO4JH924e",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# import libraries\n",
    "import cv2, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy import stats\n",
    "import random, math, sys\n",
    "import pandas as pd"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8_AJ6LIhG7uL",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "\"\"\"\n",
    "Function Name:  discretize_gt()\n",
    "Parameters: gt\n",
    "Functionality: This function\n",
    "               1) discetize the Ground Truth\n",
    "returns: discrete valued gt\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def discretize_gt(gt):\n",
    "\n",
    "\timport warnings\n",
    "\n",
    "\twarnings.warn('can improve the way GT is discretized')\n",
    "\n",
    "\treturn gt/255\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Function Name:  auc_judd()\n",
    "Parameters: s_map,gt\n",
    "Functionality: This function\n",
    "               1) Calculate the AUC score between Ground Truth and the predicted\n",
    "                  Saliency for different techniques, like Itti-koch, Deep Gaze, \n",
    "                  FCN etc.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def auc_judd(s_map,gt):\n",
    "\t# ground truth is discrete, s_map is continous and normalized\n",
    "  gt = np.ceil(discretize_gt(gt))\n",
    "  gt = np.array(gt, dtype=\"int\")\n",
    "  # print(int(np.max(gt)))\n",
    "\t# thresholds are calculated from the salience map, only at places where fixations are present\n",
    "  thresholds = []\n",
    "  for i in range(0,gt.shape[0]):\n",
    "    for k in range(0,gt.shape[1]):\n",
    "      if gt[i][k]>0:\n",
    "        thresholds.append(s_map[i][k])\n",
    "\n",
    "\n",
    "  num_fixations = np.sum(gt)\n",
    "\t# num fixations is no. of salience map values at gt >0\n",
    "\n",
    "\n",
    "  thresholds = sorted(set(thresholds))\n",
    "\n",
    "\t#fp_list = []\n",
    "\t#tp_list = []\n",
    "  area = []\n",
    "  area.append((0.0,0.0))\n",
    "  for thresh in thresholds:\n",
    "\t\t# in the salience map, keep only those pixels with values above threshold\n",
    "    temp = np.zeros(s_map.shape)\n",
    "    temp[s_map>=thresh] = 1.0\n",
    "    # print(np.max(gt))\n",
    "    assert np.max(gt)==1, 'something is wrong with ground truth..not discretized properly max value > 1'\n",
    "    assert np.max(s_map)==1, 'something is wrong with salience map..not normalized properly max value > 1'\n",
    "    num_overlap = np.where(np.add(temp,gt)==2)[0].shape[0]\n",
    "    tp = num_overlap/(num_fixations*1.0)\n",
    "\n",
    "\t\t# total number of pixels > threshold - number of pixels that overlap with gt / total number of non fixated pixels\n",
    "\t\t# this becomes nan when gt is full of fixations..this won't happen\n",
    "    fp = (np.sum(temp) - num_overlap)/((np.shape(gt)[0] * np.shape(gt)[1]) - num_fixations)\n",
    "    area.append((round(tp,4),round(fp,4)))\n",
    "\t\t#tp_list.append(tp)\n",
    "\t\t#fp_list.append(fp)\n",
    "\n",
    "\t#tp_list.reverse()\n",
    "\t#fp_list.reverse()\n",
    "  area.append((1.0,1.0))\n",
    "\t#tp_list.append(1.0)\n",
    "\t#fp_list.append(1.0)\n",
    "\t#print tp_list\n",
    "  area.sort(key = lambda x:x[0])\n",
    "  tp_list =  [x[0] for x in area]\n",
    "  fp_list =  [x[1] for x in area]\n",
    "  return np.trapz(np.array(tp_list),np.array(fp_list))\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "W5oZuA2Z96Fe",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Define your own path to the data directory\n",
    "path_to_data= \"/content/drive/My Drive/HCI_prep/Prediction_and_Analysis/\"\n",
    "\n",
    "#FiWi\n",
    "FiWi_gt = path_to_data+\"Generalization_Data/FiWi/Ground_Truth_Eyemap/\"\n",
    "FiWi_pi= path_to_data+\"Generalization_Data/FiWi/predicted_images/\"\n",
    "\n",
    "#MassVis\n",
    "MassVis_gt= path_to_data+\"Generalization_Data/Massvis/valid_imp/\"\n",
    "MassVis_pi= path_to_data+\"Generalization_Data/Massvis/predicted_image/\"\n",
    "\n",
    "#MIT\n",
    "MIT_gt= path_to_data+\"Generalization_Data/MIT_Dataset/test_gt/\"\n",
    "MIT_pi= path_to_data+\"Generalization_Data/MIT_Dataset/predicted_image/\"\n",
    "\n",
    "\n",
    "# create dictionary with the Ground truth and Predicted image for each dataset\n",
    "dir_data_pred_dict= {\"FiWI\":{\"gt\":FiWi_gt,\"pi\":FiWi_pi},\"MassVis\":{\"gt\":MassVis_gt,\"pi\":MassVis_pi},\"MIT\":{\"gt\":MIT_gt,\"pi\":MIT_pi}}\n",
    "\n",
    "  "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Up81AOqJF7Fl",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "\"\"\"\n",
    "Function Name: return_image_size()\n",
    "Functionalities: This function takes path of a predicted image and returns the \n",
    "                size of the image\n",
    "Parameter:path\n",
    "Returns: img.shape[0],img.shape[1]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def return_image_size(path):\n",
    "  img = cv2.imread(path,1)\n",
    "  img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "  return img.shape[0],img.shape[1]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Function Name: Groung_Image_Arr()\n",
    "Functionalities: 1) BGR-GRAY conversion\n",
    "                 2) Resizing to height*weight\n",
    "                 3) values range from 0 to 255\n",
    "Parameter:path, width, height,title\n",
    "Returns: label\n",
    "\"\"\"\n",
    "def Groung_Image_Arr(path, width, height,title):\n",
    "    # print(path)\n",
    "    # print(title)\n",
    "    \n",
    "    img = cv2.imread(path,1)\n",
    "    if img is None:\n",
    "      path.endswith(\".jpg\")\n",
    "      path = path.split(\".\")\n",
    "      # print(path)\n",
    "      path = path[0]+\".jpeg\"\n",
    "      img = cv2.imread(path, 1)\n",
    "      # print(img)\n",
    "    # print(img)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.resize(img, (width, height))\n",
    "    label = np.array(img, dtype=np.uint8) # values range from 0 to 255\n",
    "    #print(label.max())\n",
    "    return label\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Function Name: pred_img_Arr()\n",
    "Functionalities: 1) BGR-GRAY conversion\n",
    "                 2) Resizing to height*weight\n",
    "                 3) values range from 0 to 255\n",
    "Parameter:path, width, height,title\n",
    "Returns: label\n",
    "\"\"\"\n",
    "\n",
    "def pred_img_Arr(path, width, height,title):\n",
    "  img = cv2.imread(path,1)\n",
    "  if img is None:\n",
    "      path.endswith(\".jpg\")\n",
    "      path = path.split(\".\")\n",
    "      # print(path)\n",
    "      path = path[0]+\".jpeg\"\n",
    "      img = cv2.imread(path, 1)\n",
    "  img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "  img = cv2.resize(img, (width, height))\n",
    "  label = np.array(img, dtype=np.uint8) # values range from 0 to 255\n",
    "  #print(label.max())\n",
    "  return label\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Function Name: normalize_map()\n",
    "Functionalities: normalises the saliency map\n",
    "Parameter:s_map\n",
    "Returns: norm_s_map\n",
    "\"\"\"\n",
    "\n",
    "def normalize_map(s_map):\n",
    "\t# normalize the salience map (as done in MIT code)\n",
    "\tnorm_s_map = (s_map - np.min(s_map))/((np.max(s_map)-np.min(s_map))*1.0)\n",
    "\treturn norm_s_map\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yhodWh6RGwTG",
    "colab_type": "code",
    "outputId": "236cb013-8963-4daf-f58b-65aa57e7912f",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1581974072260,
     "user_tz": -330,
     "elapsed": 9760,
     "user": {
      "displayName": "Niloy Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAeDh1ZmOF_gqNBKQeZx-iTQhGRzkKZDJAA9so4=s64",
      "userId": "05129198731213717808"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 819
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "dict_Judd = {}\n",
    "\n",
    "# create nd array for evaluation\n",
    "for i, j in dir_data_pred_dict.items():\n",
    "\n",
    "\n",
    "  for dir_data_name, dir_data in dir_data_pred_dict[i].items():\n",
    "\n",
    "    dict_AUC_Judd = {}\n",
    "    list_AUC_Judd = []\n",
    "  \n",
    "    #print (i)\n",
    "    pred_saliency_data = os.listdir(dir_data)\n",
    "    pred_saliency_data.sort()\n",
    "   \n",
    "    \n",
    "    # Take the size of the predicted image for processing of the grund truth image \n",
    "    #(Because some models return 224*224, some models, like RF, Itti-Koch and \n",
    "    # SVM return 128*128 images)\n",
    "    input_width, input_height = return_image_size(dir_data+pred_saliency_data[0])\n",
    "  \n",
    "    # resize if predicted image size is more than 224*224\n",
    "    if input_width>224:\n",
    "      input_width, input_height = 224,224\n",
    "\n",
    "    \n",
    "    if dir_data_name ==\"gt\":\n",
    "      dir_data_gt= dir_data\n",
    "\n",
    "      # read groud data directory and sort\n",
    "      saliency_data = os.listdir(dir_data)\n",
    "      #print(\"saliency data: \", saliency_data)\n",
    "      saliency_data.sort()\n",
    "      #print(\"sorted\",saliency_data)\n",
    "      continue\n",
    "    \n",
    "    elif dir_data_name == \"pi\":\n",
    "      dir_data_pred= dir_data\n",
    "\n",
    "      # read predicted data directory and sort\n",
    "      pred_saliency_data = os.listdir(dir_data_pred)\n",
    "      pred_saliency_data.sort()\n",
    "      #print(\"sorted\",pred_saliency_data)\n",
    "          \n",
    "\n",
    "    for im in saliency_data:\n",
    "      # print(im)\n",
    "\n",
    "      #call to Groung_Image_Arr\n",
    "      gt = Groung_Image_Arr(dir_data_gt+im, input_width, input_height,im) \n",
    "\n",
    "      #call to pred_img_Arr    \n",
    "      s_map = pred_img_Arr(dir_data_pred+im, input_width, input_height,im)\n",
    "\n",
    "      # call to normalize_map\n",
    "      s_map_norm = normalize_map(s_map)\n",
    "\n",
    "     # call to calculate AUC score\n",
    "      auc_judd_score = auc_judd(s_map_norm,gt)\n",
    "      dict_AUC_Judd.update({im:auc_judd_score})\n",
    "      list_AUC_Judd.append(auc_judd_score)\n",
    "      print (im + ' auc judd :', auc_judd_score)\n",
    "\n",
    "    # take max, min and average of AUC score\n",
    "    mx_judd = max(list_AUC_Judd)\n",
    "    mn_judd = min(list_AUC_Judd)\n",
    "    avg_judd = sum(list_AUC_Judd)/len(list_AUC_Judd)\n",
    "\n",
    "   \n",
    "    # Store all the data in a dictionary\n",
    "    dic_res_judd = {}\n",
    "   \n",
    "\n",
    "    dic_res_judd[\"max\"] = mx_judd\n",
    "    dic_res_judd[\"min\"] = mn_judd\n",
    "    dic_res_judd[\"avg\"] = avg_judd\n",
    "  \n",
    "   \n",
    "\n",
    "    dict_Judd[i] = dic_res_judd\n",
    "    \n",
    "   \n",
    "  print(dict_Judd)\n",
    "  print(\"#################################################################\")\n",
    "\n",
    "\n",
    "\n",
    "# Save the result in a csv file\n",
    "df = pd.DataFrame(dict_Judd)\n",
    "df.to_csv(path_to_data+\"/Generalization_Results/\"+\"AUC_Judd_\"+\"results.csv\")\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZXC_eaEG--y4",
    "colab_type": "text"
   },
   "source": [
    "Plot the AUC score in a Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZPPjdtns-9Av",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "outputId": "cac4828a-2b6a-46e4-9b47-8e5518e4d427",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1581974072709,
     "user_tz": -330,
     "elapsed": 10187,
     "user": {
      "displayName": "Niloy Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAeDh1ZmOF_gqNBKQeZx-iTQhGRzkKZDJAA9so4=s64",
      "userId": "05129198731213717808"
     }
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "df_new=df.T\n",
    "print(df_new)\n",
    "\n",
    "#df= df.reset_index()\n",
    "import seaborn as sns\n",
    "\n",
    "fig = df_new.plot(kind='bar')\n",
    "#plt.margins(0.02)\n",
    "plt.ylabel(\"AUC_JUDD_\"+\" Score\")\n",
    "plt.xlabel('Models')\n",
    "fig.set_xticklabels(df_new.T.columns, rotation = 45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "\n",
    "#plt.grid(True)\n",
    "\n",
    "plt.savefig(path_to_data+\"/Generalization_Results/\"+\"AUC_JUDD_\"+\".png\")\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}